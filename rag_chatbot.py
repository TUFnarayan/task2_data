import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from tqdm import tqdm
import google.generativeai as genai

# âœ… Configure Gemini API (Hardcoded API Key)
genai.configure(api_key="AIzaSyDTD5bLTr8tMsHIVVvskCHgMSp0mu3bezk")

# âœ… Load FAQ data
faq_path = "rag_chatbot/data/faq_clean.csv"
df = pd.read_csv(faq_path)
print("âœ… FAQ entries loaded:", len(df))
print(df.head())

# âœ… Initialize embedding model
model = SentenceTransformer("all-MiniLM-L6-v2")

# Combine Question + Answer for better retrieval
faq_texts = (df["Question"] + " " + df["Answer"]).tolist()

# Generate embeddings
print("ğŸ” Generating embeddings...")
embeddings = model.encode(faq_texts, convert_to_numpy=True, show_progress_bar=True)

# Create FAISS index
dimension = embeddings.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)
print("âœ… FAISS index ready with", index.ntotal, "entries")

# âœ… Function to retrieve similar FAQs
def retrieve_relevant_faq(query, top_k=2):
    query_embedding = model.encode([query], convert_to_numpy=True)
    distances, indices = index.search(query_embedding, top_k)
    results = [faq_texts[i] for i in indices[0]]
    return "\n\n".join(results)

# âœ… Function to generate Gemini answer
def generate_answer_with_gemini(question, context):
    prompt = f"""
You are a helpful Aurora Skies Airways assistant.
Use ONLY the context below to answer the userâ€™s question.
If the answer isnâ€™t available in the context, respond with:
"I'm sorry, I donâ€™t have that information."

Context:
{context}

Question: {question}
"""

    try:
        # âœ… Use latest available model from your list
        model_gemini = genai.GenerativeModel("models/gemini-2.5-flash")
        response = model_gemini.generate_content(prompt)

        if hasattr(response, "text") and response.text:
            return response.text.strip()
        else:
            return "âš ï¸ No valid response text received from Gemini."

    except Exception as e:
        print("âŒ Error while generating Gemini response:", e)
        return "I'm sorry, I couldnâ€™t generate a response due to a technical issue."

# âœ… Main loop
if __name__ == "__main__":
    print("\nğŸ¤– Aurora Skies Airways Chatbot")
    print("(Type 'exit' to quit)\n")

    while True:
        user_query = input("ğŸ’¬ Ask Aurora Skies Airways (or type 'exit' to quit): ").strip()
        if user_query.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Goodbye!")
            break

        # Step 1: Retrieve relevant FAQ context
        context = retrieve_relevant_faq(user_query)
        print("\nğŸ“š Retrieved Context:\n", context)

        # Step 2: Generate response using Gemini
        answer = generate_answer_with_gemini(user_query, context)
        print("\nğŸ¤– Chatbot:\n", answer)
